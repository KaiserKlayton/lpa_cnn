It is well-known in principle that the full precision of computer hardware (e.g. 32 or 64 bit floats) is not really needed for neural networks. By design, they're robust against phenomena like small perturbations in data, stochastic activations of units (i.e. dropout), and weight randomization. Thus, there is a recent trend of moving to low-precision calculations in order to speed up inference in deep neural networks. In fact, recently designed GPUs feature an 8-bit integer mode specifically tailored for inference in deep neural networks. This would in theory run inference at 4x the speed of 32 bit floats. However, there are few studies on exactly how low precision calculations effect classification accuracy and speed at inference time. This thesis deals with the implementation of several neural network architectures in C++, analyzing how well they hold up given a change in arithmetic precision.